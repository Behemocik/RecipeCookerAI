"""
Modu≈Ç Core (Rdze≈Ñ Aplikacji).

Zawiera:
- Konfiguracjƒô globalnƒÖ i ≈Çadowanie zmiennych ≈õrodowiskowych.
- Wrapper dla klienta LLM (Groq) z obs≈ÇugƒÖ wielu kluczy API (load balancing).
- Wrapper dla wyszukiwarki Google.
- ZarzƒÖdzanie historiƒÖ (odczyt/zapis JSON).
- Logikƒô warsztatu kulinarnego (koordynacja agent√≥w).
"""

import os
import json
import asyncio
import random
import requests
from functools import partial
from dotenv import load_dotenv

# ==============================================================================
# KONFIGURACJA
# ==============================================================================

load_dotenv()

# ≈Åadowanie kluczy API Groq (obs≈Çuga wielu kluczy w celu ominiƒôcia limit√≥w Rate Limit)
GROQ_API_KEYS = []
if os.environ.get("GROQ_API_KEY"):
    GROQ_API_KEYS.append(os.environ.get("GROQ_API_KEY"))

# Obs≈Çuga dodatkowych kluczy zdefiniowanych jako GROQ_API_KEY_2, _3, itd.
for i in range(2, 11):
    key = os.environ.get(f"GROQ_API_KEY_{i}")
    if key:
        GROQ_API_KEYS.append(key)

# G≈Ç√≥wny klucz (fallback)
GROQ_API_KEY = GROQ_API_KEYS[0] if GROQ_API_KEYS else None

DISCORD_TOKEN = os.environ.get("DISCORD_TOKEN")
try:
    CHANNEL_ID = int(os.environ.get("DISCORD_CHANNEL_ID", 0))
except (ValueError, TypeError):
    CHANNEL_ID = 0

# Konfiguracja Google Search
GOOGLE_API_KEY = os.environ.get("GOOGLE_API_KEY")
GOOGLE_CX = os.environ.get("GOOGLE_CX")

# Pliki Historii
HISTORY_DIR = "memory"
MAIN_HISTORY_FILE = os.path.join(HISTORY_DIR, "main.json")  # Historia region√≥w, kuchni, ankiet
TRENDS_FILE = os.path.join(HISTORY_DIR, "trends.json")      # Historia trend√≥w
INSIGHTS_FILE = os.path.join(HISTORY_DIR, "insights.json")  # Wnioski o u≈ºytkowniku

# Sta≈Çe konfiguracyjne
MAX_INSIGHTS = 15      # Maksymalna liczba wniosk√≥w trzymanych w pamiƒôci
RECENT_REGION_COUNT = 2 # Ile ostatnich region√≥w pamiƒôtaƒá, by ich nie powtarzaƒá

# Mapowanie Region√≥w i Kuchni
# Struktura: Kontynent -> Rodzaj Kuchni -> Nazwa wy≈õwietlana (dope≈Çniacz: "do...")
CUISINE_REGIONS = {
    "Europa": {
        "W≈Çoska (Klasyczna)": "W≈Çoch",
        "W≈Çoska (Sycylia/Po≈Çudnie)": "S≈Çonecznej Sycylii",
        "Francuska (Prowansalska)": "Prowansji",
        "Francuska (Bistro)": "Pary≈ºa",
        "Hiszpa≈Ñska (Tapas/Paella)": "Hiszpanii",
        "Grecka (Tawerna)": "Grecji",
        "Polska (Staropolska)": "Szlacheckiego Dworku",
        "Polska (Bar Mleczny)": "PRL-u",
        "Ukrai≈Ñska (Wareniki/Barszcz)": "Ukrainy",
        "Gruzi≈Ñska (Supra)": "Gruzji",
        "Wƒôgierska (Papryka)": "Wƒôgier",
        "Niemiecka (Wurst/Kartoffel)": "Bawarii",
        "Skandynawska (Hygge)": "P√≥≈Çnocy",
        "Ba≈Çka≈Ñska (Grill)": "Ba≈Çkan√≥w",
    },
    "Azja": {
        "Japo≈Ñska (Ramen Shop)": "Tokio",
        "Japo≈Ñska (Domowa)": "Japonii",
        "Chi≈Ñska (Syzuana/Ostry)": "Syczuanu",
        "Chi≈Ñska (Kanto≈Ñska/DimSum)": "Kantonu",
        "Wietnamska (Street Food)": "Hanoi",
        "Tajska (Curry/PadThai)": "Bangkoku",
        "Indyjska (Curry House)": "Mumbaju",
        "Korea≈Ñska (K-Drama Food)": "Seulu",
        "Indonezyjska (Bali Vibe)": "Bali",
        "Turecka (Kebab/Meze)": "Stambu≈Çu",
        "Liba≈Ñska/Arabska": "Bejrutu",
    },
    "Ameryki": {
        "Meksyka≈Ñska (Cantina)": "Meksyku",
        "Meksyka≈Ñska (Tex-Mex)": "Pogranicza USA/Meksyk",
        "USA (Southern BBQ)": "Teksasu",
        "USA (NYC Style)": "Nowego Jorku",
        "USA (Cajun/Creole)": "Nowego Orleanu",
        "Brazylijska": "Rio de Janeiro",
        "Argenty≈Ñska": "Buenos Aires",
        "Peruwia≈Ñska": "Limon",
    },
    "Specjalne / Klimatyczne": {
        "Babcina Kuchnia (Comfort Food)": "Domu Babci",
        "Smak Jesieni (Dyniowe/Grzybowe)": "Z≈Çotej Jesieni",
    }
}

# Sp≈Çaszczona mapa kuchni
CUISINE_MAP = {k: v for region in CUISINE_REGIONS.values() for k, v in region.items()}
CUISINES = list(CUISINE_MAP.keys())


# ==============================================================================
# SERWISY (LLM & Google)
# ==============================================================================

try:
    from groq import Groq
    
    # Inicjalizacja klient√≥w Groq (po jednym na ka≈ºdy klucz API)
    GROQ_CLIENTS = []
    if GROQ_API_KEYS:
        for key in GROQ_API_KEYS:
            GROQ_CLIENTS.append(Groq(api_key=key))
            
    if not GROQ_CLIENTS:
        GROQ_CLIENT = None
    else:
        GROQ_CLIENT = GROQ_CLIENTS[0]

    def get_groq_client():
        """Zwraca losowego klienta Groq w celu roz≈Ço≈ºenia obciƒÖ≈ºenia (load balancing)."""
        if not GROQ_CLIENTS:
            return None
        return random.choice(GROQ_CLIENTS)

except ImportError:
    GROQ_CLIENT = None
    GROQ_CLIENTS = []
    def get_groq_client():
        return None

# Semafor ograniczajƒÖcy liczbƒô r√≥wnoleg≈Çych zapyta≈Ñ do LLM (zapobiega spamowaniu API)
LLM_SEMAPHORE = asyncio.Semaphore(1)

def is_google_search_configured():
    """Sprawdza, czy klucze API Google sƒÖ poprawnie skonfigurowane."""
    return bool(GOOGLE_API_KEY and GOOGLE_CX)

def google_search(query, num_results=3):
    """
    Wykonuje wyszukiwanie w Google Custom Search API.
    
    Args:
        query (str): Fraza do wyszukania.
        num_results (int): Oczekiwana liczba wynik√≥w.
        
    Returns:
        str: Po≈ÇƒÖczone fragmenty (snippets) znalezionych stron lub komunikat b≈Çƒôdu.
    """
    # Silent operation
    if not is_google_search_configured():
        print("  ‚ö†Ô∏è Brak klucza Google API")
        return "Brak danych z wyszukiwarki."
    
    url = "https://www.googleapis.com/customsearch/v1"
    params = {
        'key': GOOGLE_API_KEY,
        'cx': GOOGLE_CX,
        'q': query,
        'num': num_results
    }
    
    try:
        response = requests.get(url, params=params)
        response.raise_for_status()
        result = response.json()
        snippets = [item.get('snippet', '') for item in result.get('items', [])]
        if not snippets:
            return f"Brak wynik√≥w dla zapytania: '{query}'"
        # Silent on success
        return "\n".join(snippets)
    except requests.exceptions.HTTPError as http_err:
        error_details = response.json().get('error', {}).get('message', 'Brak szczeg√≥≈Ç√≥w')
        print(f"  ‚ùå Google API: B≈ÇƒÖd {response.status_code}")
        return f"B≈ÇƒÖd serwera Google: {error_details}"
    except Exception as e:
        print(f"  ‚ùå Google: {str(e)[:40]}")
        return f"B≈ÇƒÖd podczas wyszukiwania frazy: {query}"

async def ask_llm(messages, model="llama-3.1-8b-instant", temperature=0.7, json_mode=False):
    """
    Funkcja wysy≈ÇajƒÖca zapytanie do LLM (Groq API) z mechanizmami odporno≈õci na b≈Çƒôdy.
    
    Mechanizmy zabezpiecze≈Ñ:
    - Semaphore: Ogranicza r√≥wnoleg≈Çe wywo≈Çania API (1 na raz)
    - Retry logic: Automatyczne ponowne pr√≥by przy b≈Çƒôdzie 429 (Rate Limit)
    - Exponential backoff: Zwiƒôkszanie czasu oczekiwania miƒôdzy pr√≥bami (1s, 2s, 4s, 8s, 16s)
    - Load balancing: Je≈õli mamy wiele kluczy API, wybiera losowy
    
    Args:
        messages (list): Lista wiadomo≈õci w formacie [{"role": "system/user", "content": "..."}]
        model (str): Nazwa modelu Groq (domy≈õlnie llama-3.1-8b-instant)
        temperature (float): Kreatywno≈õƒá/losowo≈õƒá odpowiedzi (0.0=deterministyczny, 1.0=kreatywny)
        json_mode (bool): Czy wymusiƒá odpowied≈∫ w formacie JSON
        
    Returns:
        str: Odpowied≈∫ modelu (tekst lub JSON string) albo "" w przypadku b≈Çƒôdu
    """
    # WyciƒÖgamy nazwƒô agenta z system message (dla logowania)
    agent_name = messages[0].get('content', 'Agent').split('.')[0][:30]  # Max 30 znak√≥w
    
    # Pobieramy klienta Groq (mo≈ºe byƒá jeden z wielu kluczy API)
    current_client = get_groq_client()

    # Sprawdzenie czy klient jest dostƒôpny
    if not current_client:
        print(f"  ‚ö†Ô∏è LLM niedostƒôpny")
        return "{}" if json_mode else ""

    # Przygotowanie parametr√≥w wywo≈Çania API
    params = {
        "messages": messages,
        "model": model,
        "temperature": temperature,
        "max_tokens": 4096,
    }
    if json_mode:
        params["response_format"] = {"type": "json_object"}

    # Konfiguracja retry logic
    max_retries = 5
    initial_delay = 1.0

    # Semaphore zapewnia ≈ºe tylko 1 zapytanie LLM jest wysy≈Çane w danym momencie
    # (ograniczenie API rate limit)
    async with LLM_SEMAPHORE:
        delay = initial_delay
        for attempt in range(max_retries):
            try:
                # Wywo≈Çanie Groq API (blokujƒÖce, wiƒôc u≈ºywamy executor)
                blocking_task = partial(current_client.chat.completions.create, **params)
                loop = asyncio.get_running_loop()
                response = await loop.run_in_executor(None, blocking_task)
                
                # Sukces! WyciƒÖgamy tre≈õƒá odpowiedzi
                content = response.choices[0].message.content
                
                # CLEANED LOG: Tylko je≈õli sukces po retry
                if attempt > 0:
                    print(f"  ‚úì {agent_name} (pr√≥ba {attempt+1})")
                
                # Kr√≥tkie op√≥≈∫nienie dla API (dobre obyczaje)
                await asyncio.sleep(0.5)
                return content
                
            except Exception as e:
                # --- OBS≈ÅUGA B≈ÅƒòDU RATE LIMIT (429) ---
                if '429' in str(e):
                    if attempt < max_retries - 1:
                        # Mamy jeszcze pr√≥by - czekamy i ponawiamy
                        print(f"  ‚è≥ {agent_name}: Rate limit, czekam {delay:.0f}s...")
                        await asyncio.sleep(delay)
                        delay *= 2  # Exponential backoff: 1s -> 2s -> 4s -> 8s -> 16s
                    else:
                        # Sko≈Ñczy≈Çy siƒô pr√≥by
                        print(f"  ‚ùå {agent_name}: Rate limit po {max_retries} pr√≥bach")
                        break
                else:
                    # --- INNY B≈ÅƒÑD (NIE 429) ---
                    # Nie ma sensu retry - przerywamy od razu
                    print(f"  ‚ùå {agent_name}: B≈ÇƒÖd API - {str(e)[:50]}")
                    break


    return "{}" if json_mode else ""


# ==============================================================================
# ZARZƒÑDZANIE HISTORIƒÑ (PAMIƒòƒÜ)
# ==============================================================================

MAIN_KEYS = ["last_cuisines", "last_regions", "last_poll"]
TRENDS_KEYS = ["last_trends"]
INSIGHTS_KEYS = ["user_insights", "liked_trends"]

def _load_json_file(file_path, default_value):
    """Pomocnicza funkcja do bezpiecznego wczytywania JSON."""
    if not os.path.exists(file_path):
        return default_value
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
            if not content:
                return default_value
            return json.loads(content)
    except (json.JSONDecodeError, FileNotFoundError):
        return default_value

def load_history():
    """Wczytuje ca≈ÇƒÖ historiƒô (g≈Ç√≥wnƒÖ, trendy, insighty) do jednego s≈Çownika."""
    os.makedirs(HISTORY_DIR, exist_ok=True)
    
    history = {}
    
    main_data = _load_json_file(MAIN_HISTORY_FILE, {k: [] for k in MAIN_KEYS})
    trends_data = _load_json_file(TRENDS_FILE, {k: [] for k in TRENDS_KEYS})
    insights_data = _load_json_file(INSIGHTS_FILE, {k: [] for k in INSIGHTS_KEYS})
    
    history.update(main_data)
    history.update(trends_data)
    history.update(insights_data)
    
    # Inicjalizacja brakujƒÖcych kluczy
    for key in MAIN_KEYS + TRENDS_KEYS + INSIGHTS_KEYS:
        if key not in history:
            history[key] = [] if 'last' in key else {}
            
    return history

def _save_json_file(file_path, data):
    """Pomocnicza funkcja do zapisu JSON."""
    with open(file_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=4)

def save_history(history):
    """Zapisuje stan historii do odpowiednich plik√≥w JSON."""
    os.makedirs(HISTORY_DIR, exist_ok=True)
    
    main_data = {k: history.get(k) for k in MAIN_KEYS if k in history}
    trends_data = {k: history.get(k) for k in TRENDS_KEYS if k in history}
    insights_data = {k: history.get(k) for k in INSIGHTS_KEYS if k in history}
    
    _save_json_file(MAIN_HISTORY_FILE, main_data)
    _save_json_file(TRENDS_FILE, trends_data)
    _save_json_file(INSIGHTS_FILE, insights_data)

def save_daily_plan(date_str, content):
    """Zapisuje wygenerowany plan (Markdown) do pliku w folderze daily_plans."""
    os.makedirs("daily_plans", exist_ok=True)
    file_path = os.path.join("daily_plans", f"{date_str}.md")
    with open(file_path, 'w', encoding='utf-8', errors='replace') as f:
        f.write(content)
    print(f"üíæ [PLIK] Zapisano plan dzienny: {file_path}")


# ==============================================================================
# WARSZTAT KULINARNY (KOORDYNACJA AGENT√ìW)
# ==============================================================================

async def culinary_workshop(trend, cuisine, daily_brief, insights_list):
    """
    Warsztat kulinarny - iteracyjny proces tworzenia przepisu.
    
    Proces: Chef -> Logistyk -> Dietetyk -> (je≈õli odrzucono: powt√≥rz z feedbackiem)
    Maksymalnie 3 iteracje.
    """
    from agents.workshop import agent_chef_refiner, agent_shopper_audit, agent_nutrition_audit
    
    # Przygotowanie draftu przepisu
    draft = {
        "idea": trend, "cuisine": cuisine,
        "guidelines": {"daily_brief": daily_brief, "user_insights": insights_list},
        "feedback_history": [], "chef_work": {}, "final_macros": {}
    }
    MAX_ITERATIONS = 3
    
    # Iteracje warsztatu (maksymalnie 3)
    for i in range(MAX_ITERATIONS):
        # --- CHEF ---
        chef_response_str = await agent_chef_refiner(draft)
        try: 
            chef_response = json.loads(chef_response_str)
        except (json.JSONDecodeError, TypeError): 
            chef_response = None
        
        if not chef_response or not isinstance(chef_response, dict) or not chef_response.get("dish_name"):
            draft["feedback_history"].append("B≈ÇƒÖd formatu JSON")
            continue
            
        draft["chef_work"] = chef_response
        dish = chef_response.get('dish_name', '')[:30]  # Skr√≥cona nazwa
        print(f"  ‚úì '{dish}'")

        # --- LOGISTYK ---
        shopper_review_str = await agent_shopper_audit(draft)
        try: 
            shopper_review = json.loads(shopper_review_str)
        except (json.JSONDecodeError, TypeError): 
            shopper_review = None

        if not isinstance(shopper_review, dict) or not shopper_review.get("approved", False):
            feedback = f"Logistyk: {shopper_review.get('feedback', 'Odrzucony') if isinstance(shopper_review, dict) else 'B≈ÇƒÖd'}"
            draft["feedback_history"].append(feedback)
            print(f"  ‚úó Odrzucono (logistyk)")
            continue

        # --- DIETETYK ---
        nutrition_review_str = await agent_nutrition_audit(draft)
        try: 
            nutrition_review = json.loads(nutrition_review_str)
        except (json.JSONDecodeError, TypeError): 
            nutrition_review = None

        if not isinstance(nutrition_review, dict) or not nutrition_review.get("approved", False):
            feedback = f"Dietetyk: {nutrition_review.get('feedback', 'Odrzucony') if isinstance(nutrition_review, dict) else 'B≈ÇƒÖd'}"
            draft["feedback_history"].append(feedback)
            print(f"  ‚úó Odrzucono (dietetyk)")
            continue
        
        # SUKCES - wszystkie audyty przesz≈Çy!
        draft["final_macros"] = {"calories": nutrition_review.get("calories", "?")}
        return draft["chef_work"], draft["final_macros"]

    # Pora≈ºka po MAX_ITERATIONS pr√≥bach
    return None, None
